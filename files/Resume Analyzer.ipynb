{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57a39733-e501-4936-92f9-8b413edbb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scrapping using Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ee39ad7-bcb5-4aea-a410-8a085516c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Edge WebDriver\n",
    "options = webdriver.EdgeOptions()  \n",
    "options.use_chromium = True \n",
    "# options.add_argument(\"--headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e71d9504-02ad-42c8-9004-de866969b672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page 1...\n",
      "Scraping Page 2...\n",
      "Scraping Page 3...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Brief JD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Aloden Inc —Remote</td>\n",
       "      <td>Support *CMS certification activities*, includ...</td>\n",
       "      <td>Jira, Microsoft Excel, Waterfall, Enterprise s...</td>\n",
       "      <td>Job Title: Certification Data Analyst\\nLocatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst (Remote)</td>\n",
       "      <td>Latica —Palo Alto, CA</td>\n",
       "      <td>The Latica medical data science platform bring...</td>\n",
       "      <td>Research, Mid-level, SQL, Pandas, AWS, 2 years...</td>\n",
       "      <td>Who We Are?\\nLatica (Formerly Lynx.MD) is buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Warehouse Analyst</td>\n",
       "      <td>ASSYST, Inc. —Tallahassee, FL</td>\n",
       "      <td>Coach and mentor peers in data warehousing con...</td>\n",
       "      <td>Computer science, Power BI, 7 years, Business ...</td>\n",
       "      <td>ASSYST is seeking a skilled Data Warehouse Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst (Excel)</td>\n",
       "      <td>StellarMettle Placements —Duluth, GA</td>\n",
       "      <td>Experience in data analysis, reporting, or bus...</td>\n",
       "      <td>Microsoft Excel, Business intelligence, Data a...</td>\n",
       "      <td>We are seeking a highly skilled Data Analyst w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entry-Level Data Analyst</td>\n",
       "      <td>Upen Group Inc —Irving, TX</td>\n",
       "      <td>*Bachelor’s degree* in Data Science, Statistic...</td>\n",
       "      <td>Power BI, Microsoft Excel, Data analysis skill...</td>\n",
       "      <td>Entry-Level Data Analyst – Uncover Insights an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title                               Company  \\\n",
       "0              Data Analyst                    Aloden Inc —Remote   \n",
       "1     Data Analyst (Remote)                 Latica —Palo Alto, CA   \n",
       "2    Data Warehouse Analyst         ASSYST, Inc. —Tallahassee, FL   \n",
       "3      Data Analyst (Excel)  StellarMettle Placements —Duluth, GA   \n",
       "4  Entry-Level Data Analyst            Upen Group Inc —Irving, TX   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Support *CMS certification activities*, includ...   \n",
       "1  The Latica medical data science platform bring...   \n",
       "2  Coach and mentor peers in data warehousing con...   \n",
       "3  Experience in data analysis, reporting, or bus...   \n",
       "4  *Bachelor’s degree* in Data Science, Statistic...   \n",
       "\n",
       "                                       Qualification  \\\n",
       "0  Jira, Microsoft Excel, Waterfall, Enterprise s...   \n",
       "1  Research, Mid-level, SQL, Pandas, AWS, 2 years...   \n",
       "2  Computer science, Power BI, 7 years, Business ...   \n",
       "3  Microsoft Excel, Business intelligence, Data a...   \n",
       "4  Power BI, Microsoft Excel, Data analysis skill...   \n",
       "\n",
       "                                            Brief JD  \n",
       "0  Job Title: Certification Data Analyst\\nLocatio...  \n",
       "1  Who We Are?\\nLatica (Formerly Lynx.MD) is buil...  \n",
       "2  ASSYST is seeking a skilled Data Warehouse Ana...  \n",
       "3  We are seeking a highly skilled Data Analyst w...  \n",
       "4  Entry-Level Data Analyst – Uncover Insights an...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start WebDriver\n",
    "driver = webdriver.Edge(service=Service(EdgeChromiumDriverManager().install()), options=options)\n",
    "\n",
    "# Open Indeed Jobs Page\n",
    "job_title = \"Data Analyst\"\n",
    "location = \"United States\"\n",
    "url = f\"https://www.simplyhired.com/search?q={job_title}&l={location}\"\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(10) \n",
    "\n",
    "# Extract Job Data\n",
    "jobs = []\n",
    "q_jobs = []\n",
    "max_pages = 3  #Adjust based on requirement\n",
    "current_page = 1 \n",
    "\n",
    "\n",
    "while current_page <= max_pages:\n",
    "    print(f\"Scraping Page {current_page}...\") \n",
    "\n",
    "    job_cards = driver.find_elements(By.CLASS_NAME, \"css-0\") \n",
    "\n",
    "    for job in job_cards:\n",
    "        try:\n",
    "            title = job.find_element(By.CLASS_NAME, \"css-1djbb1k\").text.strip() \n",
    "            company = job.find_element(By.CLASS_NAME, \"css-1sawo7p\").text.strip() \n",
    "            description = job.find_element(By.CLASS_NAME, \"css-jhqp7z\").text.strip() \n",
    "\n",
    "            try:\n",
    "                job.click()\n",
    "                time.sleep(5) \n",
    "                qualifications = job.find_elements(By.XPATH, \"//span[@data-testid='viewJobQualificationItem']\")\n",
    "                qualification = [q.text for q in qualifications]\n",
    "                qualification = \", \".join(qualification)\n",
    "                brief_jd = job.find_elements(By.XPATH, \"//div[@data-testid='viewJobBodyJobFullDescriptionContent']\")[0].text\n",
    "              \n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            jobs.append({\"Title\": title, \"Company\": company, \"Description\": description, \"Qualification\": qualification, \"Brief JD\": brief_jd})\n",
    "  \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, \"//a[@aria-label='Next page']\")\n",
    "        next_button.click()\n",
    "        time.sleep(10)  \n",
    "        current_page += 1\n",
    "    except:\n",
    "        print(\"No more pages available or next button not found.\")\n",
    "        break \n",
    "\n",
    "df = pd.DataFrame(jobs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24930823-afef-4e7d-950a-7833118c98c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            0\n",
       "Company          0\n",
       "Description      0\n",
       "Qualification    0\n",
       "Brief JD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03257271-6da8-46fd-8e7a-a6f92f2105f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Title          60 non-null     object\n",
      " 1   Company        60 non-null     object\n",
      " 2   Description    60 non-null     object\n",
      " 3   Qualification  60 non-null     object\n",
      " 4   Brief JD       60 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check for datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "342f1dcc-69d9-40a5-8b01-668d5ac57747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a29e28ee-1263-4461-8d5d-fc7a394c9921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balaj\\AppData\\Local\\Temp\\ipykernel_1212\\1648060196.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# ️Standardize text data to remove extra spaces, lower case\n",
    "df = df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6fa332-a256-4c51-bd07-6b77ed468170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b98663ec-8df2-44f4-8d5d-fe0d5d0dea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define skillset for Data Analyst\n",
    "skills = [\n",
    "    \"Python\", \"SQL\", \"R\", \"SAS\", \"Power BI\", \"Tableau\", \"Looker\",\n",
    "    \"QlikView\", \"Google Data Studio\", \"MySQL\", \"PostgreSQL\", \"Microsoft SQL Server\",\n",
    "    \"Oracle\", \"Snowflake\", \"BigQuery\", \"Pandas\", \"NumPy\", \"Excel\", \"VBA\", \"DAX\",\n",
    "    \"T-SQL\", \"Regression Analysis\", \"Hypothesis Testing\", \"Time Series Analysis\",\n",
    "    \"Forecasting\", \"Clustering\", \"Predictive Analytics\", \"AWS\", \"Azure\", \"Google Cloud\",\n",
    "    \"Hadoop\", \"Spark\", \"Databricks\", \"Business Intelligence\", \"KPI Analysis\",\n",
    "    \"Data Warehousing\", \"ETL\", \"Reporting Automation\", \"Problem Solving\",\n",
    "    \"Communication\", \"Critical Thinking\", \"Storytelling with Data\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2572e346-b927-4036-89dd-b9a042942582",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = [skill.lower() for skill in skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadb5f2-71ae-4397-8a8d-0feab790c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill Extraction with RegEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "17fea51a-e0e7-4ad5-9c2c-446bea934320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_skills(text, skill_list):\n",
    "    if pd.isna(text): \n",
    "        return []\n",
    "    found_skills = [skill for skill in skill_list if re.search(rf'\\b{re.escape(skill)}\\b', text, re.IGNORECASE)]\n",
    "    return found_skills\n",
    "\n",
    "df['extracted_skills'] = df['Brief JD'].apply(lambda x: extract_skills(x, skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95ed03-e1d2-4eed-903a-6f9cd24735ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill Extraction with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "123861c7-a904-47c0-a6dc-9ecb7d51be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Add custom skills to match Spacy's PhraseMatcher\n",
    "skill_patterns = [\n",
    "    \"hypothesis testing\", \"power bi\", \"data warehousing\", \n",
    "    \"business intelligence\", \"problem solving\", \n",
    "    \"regression analysis\", \"critical thinking\"\n",
    "]\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "patterns = [nlp(skill) for skill in skill_patterns]\n",
    "matcher.add(\"SKILL\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fcaaa62b-0948-44bf-a7b4-35cab131672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract skills using both Spacy and custom matcher\n",
    "def extract_skills_nlp(text):\n",
    "    doc = nlp(text.lower())\n",
    "    found_skills = set()\n",
    "    \n",
    "    # Extract skills from Named Entities\n",
    "    for token in doc:\n",
    "        if token.text in skills:\n",
    "            found_skills.add(token.text)\n",
    "            \n",
    "    # Extract skills from custom matcher\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        found_skills.add(doc[start:end].text.lower())\n",
    "\n",
    "    return list(found_skills)\n",
    "\n",
    "df['extracted_skills_spacy'] = df['Brief JD'].apply(extract_skills_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf128d-d8ea-4ab6-a689-299ded95c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare RegEx and NLP extracted skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1e17b88-d58f-433c-bb02-d970d350e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Skill  Count\n",
      "2                     sql     38\n",
      "12          communication     30\n",
      "0                   excel     25\n",
      "6                 tableau     23\n",
      "5                power bi     20\n",
      "1                  python     19\n",
      "9   business intelligence     13\n",
      "14                      r     12\n",
      "4                     aws      8\n",
      "23            forecasting      6\n"
     ]
    }
   ],
   "source": [
    "# FROM RegExp\n",
    "from collections import Counter\n",
    "all_skills = sum(df['extracted_skills'], [])  # Flatten list\n",
    "skill_counts = Counter(all_skills)\n",
    "\n",
    "skill_df = pd.DataFrame(skill_counts.items(), columns=['Skill', 'Count']).sort_values(by=\"Count\", ascending=False)\n",
    "\n",
    "print(skill_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "505d5556-1b19-4a10-b08d-b5ee435912e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Skill  Count\n",
      "2                     sql     38\n",
      "12          communication     30\n",
      "0                   excel     25\n",
      "6                 tableau     23\n",
      "5                power bi     20\n",
      "1                  python     19\n",
      "9   business intelligence     13\n",
      "14                      r     12\n",
      "4                     aws      8\n",
      "23            forecasting      6\n"
     ]
    }
   ],
   "source": [
    "# FROM NLP\n",
    "from collections import Counter\n",
    "all_skills_nlp = sum(df['extracted_skills_spacy'], [])  # Flatten list\n",
    "skill_counts_ = Counter(all_skills)\n",
    "\n",
    "skill_df_nlp = pd.DataFrame(skill_counts.items(), columns=['Skill', 'Count']).sort_values(by=\"Count\", ascending=False)\n",
    "\n",
    "print(skill_df_nlp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92739930-e15e-49a4-a146-7e1d041a67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both results to sets for easy comparison\n",
    "regex_skills_set = set(skill_df['Skill']) \n",
    "nlp_skills_set = set(skill_df_nlp['Skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "546c714c-837f-4d14-9021-a47836ac4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing skills in NLP\n",
    "missing_in_nlp = regex_skills_set - nlp_skills_set \n",
    "missing_in_regex = nlp_skills_set - regex_skills_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "29c9257c-9f4d-416a-9953-22bea65c208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total skills extracted using RegEx: 27\n",
      "Total skills extracted using NLP: 27\n",
      "Skills missing in NLP: set()\n",
      "Skills missing in RegEx: set()\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Total skills extracted using RegEx: {len(regex_skills_set)}\")\n",
    "print(f\"Total skills extracted using NLP: {len(nlp_skills_set)}\")\n",
    "print(f\"Skills missing in NLP: {missing_in_nlp}\")\n",
    "print(f\"Skills missing in RegEx: {missing_in_regex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e701e1-620c-4bc4-870f-bf9360792f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Skills from Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "60f5989f-95c5-4d8b-aa39-b658d5056ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ralf Kendal\n",
      "Phone: (888)555-1111\n",
      "Email:name@email.com\n",
      "Professional Objective\n",
      "To use my decade of experience as a data analyst to manage large sets of data, and produce insights to help the Illinois\n",
      "Department of Natural Resources achieve its objectives.\n",
      "Skills\n",
      "• SQL\n",
      "• Python\n",
      "• Evaluating data sets for integrity\n",
      "• Data cleansing and preparation for analytics\n",
      "• Gathering and understanding of user requirements\n",
      "• Visualizing and interpreting reports\n",
      "• Identifying potential risks and sources of data corruption\n",
      "Professional Experience\n",
      "Oleson Fisheries Management\n",
      "Senior Data Analyst\n",
      "June 2017 — Present\n",
      "• Provided data analysis and other support functions to various research teams, and other business areas.\n",
      "• Cleaned and anonymized nearly 5 terabytes of data.\n",
      "• Monitors data transfers and backups.\n",
      "• Uses SQL and other tools to create comprehensive data reports.\n",
      "• Manages the collection, storage, and analysis of aquatic life for facilities across five states.\n",
      "University of Iowa: Life Sciences Department\n",
      "Data Analyst\n",
      "March 2013 – June 2017\n",
      "• Assisted in collecting, cleaning, and analyzing data for various research projects.\n",
      "• Performed data server management.\n",
      "• Interpreted reports for professors, researchers, and other staff members.\n",
      "Education\n",
      "Georgia Tech\n",
      "Master of Science: Information Technology\n",
      "Emphasis: Data Analytics\n",
      "June 2012\n",
      "Davis University\n",
      "Bachelor of Science: Computer Information Systems\n",
      "January 2008\n",
      "Certification\n",
      "• Certified SQL in Advance level by Hackerrank\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Example Usage\n",
    "pdf_path = \"data-analyst-resume-example.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "print(resume_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e18d236d-934b-4345-b322-de2c69f991c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• SQL\n",
      "• Python\n",
      "• Evaluating data sets for integrity\n",
      "• Data cleansing and preparation for analytics\n",
      "• Gathering and understanding of user requirements\n",
      "• Visualizing and interpreting reports\n",
      "• Identifying potential risks and sources of data corruption\n"
     ]
    }
   ],
   "source": [
    "# Extract Only the \"Skills\" Section\n",
    "pattern = r'Skills(.*?)(?=\\n(?:Professional Experience|Education|Certification|Achievement|Project)|$)'\n",
    "\n",
    "match = re.search(pattern, resume_text, re.DOTALL)\n",
    "\n",
    "if match:\n",
    "    skill_resume = match.group(1).strip()\n",
    "    print(skill_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1bf1fac6-7a6e-4ea9-aa9e-edf0b5806037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert extracted text into a list\n",
    "resume_skills = [skill.strip() for skill in skill_resume.split(\"\\n\") if skill.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ea82712-50b1-46ad-bb2a-9002096b163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters (like •) and trim spaces\n",
    "cleaned_skills = [re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", skill).strip() for skill in resume_skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1436f50a-60e1-44ea-836d-6f94fc533d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SQL',\n",
       " 'Python',\n",
       " 'Evaluating data sets for integrity',\n",
       " 'Data cleansing and preparation for analytics',\n",
       " 'Gathering and understanding of user requirements',\n",
       " 'Visualizing and interpreting reports',\n",
       " 'Identifying potential risks and sources of data corruption']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676562e-9291-4588-880d-916768d62d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Matching and Missing Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5e88813e-a760-4e36-b1a3-c49d0fbd130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_skills = [x.lower() for x in cleaned_skills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d5a9b8f-50c5-4b4f-b6f3-7820ea0c32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_skills = set(cleaned_skills)\n",
    "job_skills = set(skill_df_nlp['Skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "52edf513-de8f-4c87-b19a-f80d68bb22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_skills = resume_skills.intersection(job_skills)\n",
    "missing_skills = job_skills - resume_skills "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "522356ea-78f7-4c1a-b199-f7abba524f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Skills: ['sql', 'python']\n",
      "Missing Skills: ['forecasting', 'postgresql', 'microsoft sql server', 'data warehousing', 'snowflake', 'looker', 'google cloud', 'critical thinking', 'oracle', 'tableau', 'r', 'aws', 'vba', 'business intelligence', 'dax', 'pandas', 'azure', 'excel', 'predictive analytics', 'communication', 'sas', 'regression analysis', 'power bi', 'problem solving', 'etl']\n",
      "Skill Match Percentage: 7.41%\n"
     ]
    }
   ],
   "source": [
    "# Calculate match percentage\n",
    "match_percentage = round((len(matching_skills) / len(job_skills)) * 100, 2)\n",
    "\n",
    "# Display results\n",
    "print(f\"Matching Skills: {list(matching_skills)}\")\n",
    "print(f\"Missing Skills: {list(missing_skills)}\")\n",
    "print(f\"Skill Match Percentage: {match_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387f2cd-1071-4f16-b4b4-eb810ae86afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly same steps can be applied to find Experience, Education, Certification \n",
    "# and Keywords from both Job description and Resume for comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
